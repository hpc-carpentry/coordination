# HPCC Coworking Hours: 2 December 2021

The HPC Carpentries Task Force holds coworking hours on the first Thursday,
with two time slots intended to provide adequate coverage for our global
constituency. These two meeting times provide the least-painful coverage for
the six non-polar continents. Folks in Antarctica and aboard a space station
are invited to join whichever is most convenient.

- [12:00 UTC][earlier] &mdash; better for Africa, Asia, and Europe
  - _N.B.:_ Shifted +1 hour for standard time!
- [22:00 UTC][evening] &mdash; better for the Americas and Oceania

A Google calendar has been set up to capture these events, available
[online][gcal] and for [download][ical] for your calendar app.

<!-- Info & Callback links -->

[meet]: https://meet.google.com/gez-aeui-jdx
[phone]: https://tel.meet/gez-aeui-jdx?hs=5
[earlier]:
  https://www.timeanddate.com/worldclock/fixedtime.html?iso=20211202T1200&msg=HPC+Carpentries+Coworking+Hour+1
[evening]:
  https://www.timeanddate.com/worldclock/fixedtime.html?iso=20211202T2200&msg=HPC+Carpentries+Coworking+Hour+2
[last-cowork]: https://codimd.carpentries.org/UU3IR5v_S3WmQXFWkQe1XA?view
[last-coord]: https://codimd.carpentries.org/sPz2XZOSRia4-5Qb36J86g?view

## VTC: **_[Click here to join!][meet]_**

Both meetings will use [Google Meet][meet]. You may also call in by [phone].

#### Previous Meetings for Reference

- [Previous Coworking Hour][last-cowork]
- [Previous Coordination Meeting][last-coord]
- [Archive of old Minutes][minutes]

---

## Earlier Meeting (Africa, Asia, and Europe)

### Participants

- _name (pronouns), affiliation_
- Trevor Keller (they/them), NIST
- Andrew Reid (he/him), NIST
- Annajiat Alim Rasel (he/him), BracU

### Agenda with Minutes

> For the sake of clarity, please take notes _directly inline_ with the agenda,
> rather than in a separate section. Thanks!

#### SC21 BoF

Our BOF at SC21 was a hit! 20 attendees in person and 40 online. Notes &
comments are in the
[BOF CodiMD](https://codimd.carpentries.org/9-Y8OaVIT2qpb_P47TR7Lw#Notes-amp-Miscellany).

- [name=Annajiat]: make a Carpentries blog post about the BOF! (Brilliant!)
  - Create a restricted shared doc, edit until we're happy, then magically loop
    in the Carpentries team to refine.
  - We should also create a post on hpc-carpentry.org
- [name=Andrew]
  [Slido Poll Results](https://github.com/hpc-carpentry/coordination/blob/main/conferences/SC21/poll-results.pdf)

  - https://community.sli.do/analytics-and-exports-44/format-your-poll-and-question-exports-489

- [name=Trevor] did a thing! New "roadmap" project, which we can use to sort
  out what we want to do with the BOF feedback.
  https://github.com/hpc-carpentry/coordination/projects/1

Numerous new issues were created in the coordination repo to capture the BoF
feedback and translate it to repo activities. A reasonable next pass is to go
through the comments captured in the
[BoF Codi](https://codimd.carpentries.org/9-Y8OaVIT2qpb_P47TR7Lw) and ensure
that valuable feedback from those is also similarly captured in the
coordination repo.

---

## Later Meeting (Americas and Oceania)

### Participants

- _name (pronouns), affiliation_
- Trevor Keller (they/them), NIST
- Andrew Reid (he/him), NIST
- Alex Razoumov, WestGrid / Compute Canada
- Wirawan Purwanto

### Agenda with Minutes

> For the sake of clarity, please take notes _directly inline_ with the agenda,
> rather than in a separate section. Thanks!

#### SC21 BoF

Our BOF at SC21 was a hit! 20 attendees in person and 40 online. Notes &
comments are in the
[BOF CodiMD](https://codimd.carpentries.org/9-Y8OaVIT2qpb_P47TR7Lw#Notes-amp-Miscellany).

Chapel: https://github.com/hpc-carpentry/coordination/issues/86

##### Historical Review & Chapel from Alex

HPC Carpentry started with Intro (parallel frameworks: OpenMP, MPI, Dask) and
Language repositories (Python, Chapel, ...). Idea is to have a common starting
point, then quickly branch into numerous frameworks valuable to specific
communities (astro, bioinformatics, materials, ...).

- Chapel allowed folks to teach in one day the basics of parallel profiling,
  where other frameworks require a much longer workshop to cover the topics
  <https://wgtm21.netlify.app/parallel_chapel/>
- Julia provides similar power; has been using it for ~1 year with a similar
  curriculum <https://wgpages.netlify.app/parallel_julia>
- Teaching an MPI lesson wouldn't let the students go & write code the next
  day, but higher-level frameworks like Chapel & Julia do.
- The lower-level frameworks/languages are also very important! They just can't
  cover as much ground in the short duration available.
- [name=Alex] Chapel allows access to MPI at many levels, including very low
  levels to explore foundational issues, or at higher levels if that meets your
  instructional requirement.

Possibly useful resources for convincing ourselves & reluctant learners of the
utility of Chapel:

- https://chapel-for-python-programmers.readthedocs.io
- https://chapel-lang.org/presentations/SIAM-AN21.pdf

(Comment on deployment of Chapel: Arkouda --
https://github.com/Bears-R-Us/arkouda)

Parallel Julia vs Chapel: Julia can do a lot of things, but there are a lot of
caveats to accomplish things. Some external libraries it depended upon (e.g.
distributed arrays) are not well polished yet. Ex: cannot do a distributed
array of structures, ...

Julia: more dispatch-oriented; harder to parallelize than Python, which itself
is not notoriously parallelizable.

Weighing feedback from SC21:

- Could be biased toward segment of community that does not represent the
  people we want to draw learners from.
- But could capture much input from HPC operators (which have some interests)

Follow-up issues (as next steps to SC21 input):

[Lessons should work with multiple durations #97](https://github.com/hpc-carpentry/coordination/issues/97)

##### Use of containers?

- Strong interest in containers & cloud resources.
- Example use case at NIST: stood a workflow involving WIPP (web image
  processing portal). Using Docker container w/ GPU to run the tools => can be
  plumbed as part of a greater pipeline, which includes running part of the
  computation on containers. Kubernetes-driven; Andrew working on the
  Kubernetes-SLURM interfacing. On HPC runs as singularity container.

Today it is very easy to spin up HPC on the cloud (e.g. a virtual cluster w/
SLURM etc). But people do not know what to do with it. Some people (w/o access
to established HPC such as XSEDE, DOE machines) that do have need the raw
computing power of HPC occassionaly, so there is a legitimate

- We should (or could?) develop a lesson on how to properly allocate &
  configure a cluster on _insert favorite cloud_. Esp. useful to those who need
  transient resources (large compute, once a year).

Open Question (Andrew): What are the levels of the intro lessons on XSEDE?
Where do we (HPC Carpentry) fit in this ecosystem?

- XSEDE training overview: https://portal.xsede.org/training/overview
- XSEDE course catalog: https://portal.xsede.org/training/course-catalog
- TACC:
  - https://www.youtube.com/channel/UCIyVQ1bICGCggZisXBSSRlw/playlists
  - https://portal.tacc.utexas.edu/training/training-materials

Candidate people to engage: (Shodor Foundation, TACC, NCSA...); prior people
that were early pioneers of HPC Carpentry in the US; Check on them for input:

- What are the priority needs of HPC users in terms of foundational training?
- Which community can we serve the best?
- Which lesson(s) should be prioritized.
- Refer to questions in BOF

##### Process for sharing feedback from teaching HPC Carpentry materials

Create an issue at the respective lesson repo (with tag: \_\_\_\_) for sharing
experience from workshop related to a specific lesson. Currently no established
place to share experience from workshop.

---

[gcal]:
  https://calendar.google.com/calendar/?cid=bWp0ZWh0ZmEycmVjZGZtNmZjdGUwMWVhdGNAZ3JvdXAuY2FsZW5kYXIuZ29vZ2xlLmNvbQ
[ical]:
  https://calendar.google.com/calendar/ical/mjtehtfa2recdfm6fcte01eatc%40group.calendar.google.com/public/basic.ics
[minutes]: https://github.com/hpc-carpentry/coordination/tree/main/minutes
[website]: https://github.com/hpc-carpentry/hpc-carpentry.github.io

<!--HPC Carpentry Repositories-->

[coordination]: https://github.com/hpc-carpentry/coordination
[proposals]: https://github.com/hpc-carpentry/coordination/labels/proposal
[hpc-chapel]: https://github.com/hpc-carpentry/hpc-chapel
[hpc-intro]: https://github.com/carpentries-incubator/hpc-intro
[hpc-parallel]: https://github.com/hpc-carpentry/hpc-parallel-novice
[hpc-python]: https://github.com/hpc-carpentry/hpc-python
[hpc-shell]: https://github.com/hpc-carpentry/hpc-shell

<!--HPC Carpentry Issues-->

[coordination-issues]: https://github.com/hpc-carpentry/coordination/issues
[hpc-chapel-issues]: https://github.com/hpc-carpentry/hpc-chapel/issues
[hpc-intro-issues]: https://github.com/carpentries-incubator/hpc-intro/issues
[hpc-parallel-issues]:
  https://github.com/hpc-carpentry/hpc-parallel-novice/issues
[hpc-python-issues]: https://github.com/hpc-carpentry/hpc-python/issues
[hpc-shell-issues]: https://github.com/hpc-carpentry/hpc-shell/issues

<!--Carpentries References-->

[conduct]:
  https://docs.carpentries.org/topic_folders/policies/code-of-conduct.html
[invite]: https://swc-slack-invite.herokuapp.com/
[license]: https://creativecommons.org/licenses/by/4.0/
[slack]: https://swcarpentry.slack.com
